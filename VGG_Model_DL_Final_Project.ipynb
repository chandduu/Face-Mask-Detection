{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Xtn8x-eZLVtd"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import cv2\n",
    "from scipy.spatial import distance\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import load_model\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "YjDy8Kt-LdU_"
   },
   "outputs": [],
   "source": [
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "from keras import Sequential\n",
    "from keras.layers import Flatten, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "eRuqJDIGL1gl"
   },
   "outputs": [],
   "source": [
    "train_dir = r'C:\\Users\\jspc8\\Downloads\\Behind the Mask\\Behind the Mask\\train'\n",
    "test_dir = r'C:\\Users\\jspc8\\Downloads\\Behind the Mask\\Behind the Mask\\test'\n",
    "#val_dir = '/content/Face Mask Dataset/Validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x6PbzHdxMDEo",
    "outputId": "f6c85baf-573f-4284-c7a9-7de7768d7b79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2646 images belonging to 2 classes.\n",
      "Found 1146 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1.0/255, horizontal_flip=True, zoom_range=0.2,shear_range=0.2)\n",
    "train_generator = train_datagen.flow_from_directory(directory=train_dir,target_size=(128,128),class_mode='categorical',batch_size=32)\n",
    "\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "test_generator = train_datagen.flow_from_directory(directory=test_dir,target_size=(128,128),class_mode='categorical',batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cpjEDTIiMMit",
    "outputId": "8db361aa-8ef5-4a32-da2f-e6972eed484d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg19 (Functional)          (None, 4, 4, 512)         20024384  \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 16386     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,040,770\n",
      "Trainable params: 16,386\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg19 = VGG19(weights='imagenet',include_top=False,input_shape=(128,128,3))\n",
    "\n",
    "for layer in vgg19.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "model = Sequential()\n",
    "model.add(vgg19)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2,activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "nCzjlvZVMTYs"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras;    \n",
    "from tensorflow.keras import metrics;\n",
    "model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\", metrics=['acc', keras.metrics.Precision(), keras.metrics.Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h2UL5ElGMW82",
    "outputId": "8db4fe44-6f86-4c5b-9162-2c2db40e552d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jspc8\\AppData\\Local\\Temp/ipykernel_19796/3469203096.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(generator=train_generator,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "2/2 [==============================] - 9s 6s/step - loss: 0.6618 - acc: 0.6406 - precision_2: 0.5833 - recall_2: 0.1094 - val_loss: 0.7219 - val_acc: 0.4688 - val_precision_2: 0.8235 - val_recall_2: 0.4375\n",
      "Epoch 2/15\n",
      "2/2 [==============================] - 8s 5s/step - loss: 0.6327 - acc: 0.5938 - precision_2: 0.8800 - recall_2: 0.3438 - val_loss: 0.4116 - val_acc: 0.9062 - val_precision_2: 1.0000 - val_recall_2: 0.3125\n",
      "Epoch 3/15\n",
      "2/2 [==============================] - 8s 5s/step - loss: 0.4460 - acc: 0.8125 - precision_2: 1.0000 - recall_2: 0.3281 - val_loss: 0.3717 - val_acc: 0.8125 - val_precision_2: 1.0000 - val_recall_2: 0.5000\n",
      "Epoch 4/15\n",
      "2/2 [==============================] - 8s 5s/step - loss: 0.4205 - acc: 0.8281 - precision_2: 1.0000 - recall_2: 0.4688 - val_loss: 0.3406 - val_acc: 0.9375 - val_precision_2: 1.0000 - val_recall_2: 0.2812\n",
      "Epoch 5/15\n",
      "2/2 [==============================] - 8s 5s/step - loss: 0.3089 - acc: 0.9375 - precision_2: 0.9688 - recall_2: 0.4844 - val_loss: 0.3807 - val_acc: 0.8125 - val_precision_2: 0.9412 - val_recall_2: 0.5000\n",
      "Epoch 6/15\n",
      "2/2 [==============================] - 8s 5s/step - loss: 0.3338 - acc: 0.8750 - precision_2: 0.9500 - recall_2: 0.5938 - val_loss: 0.2460 - val_acc: 0.9062 - val_precision_2: 1.0000 - val_recall_2: 0.5938\n",
      "Epoch 7/15\n",
      "2/2 [==============================] - 7s 4s/step - loss: 0.2629 - acc: 0.9259 - precision_2: 0.9722 - recall_2: 0.6481 - val_loss: 0.3457 - val_acc: 0.8125 - val_precision_2: 0.9474 - val_recall_2: 0.5625\n",
      "Epoch 8/15\n",
      "2/2 [==============================] - 8s 5s/step - loss: 0.2023 - acc: 0.9688 - precision_2: 1.0000 - recall_2: 0.7031 - val_loss: 0.2778 - val_acc: 0.9062 - val_precision_2: 0.9474 - val_recall_2: 0.5625\n",
      "Epoch 9/15\n",
      "2/2 [==============================] - 8s 5s/step - loss: 0.2013 - acc: 0.9219 - precision_2: 1.0000 - recall_2: 0.7031 - val_loss: 0.1491 - val_acc: 0.9688 - val_precision_2: 1.0000 - val_recall_2: 0.8125\n",
      "Epoch 10/15\n",
      "2/2 [==============================] - 8s 5s/step - loss: 0.2037 - acc: 0.9375 - precision_2: 0.9808 - recall_2: 0.7969 - val_loss: 0.3132 - val_acc: 0.8750 - val_precision_2: 0.9600 - val_recall_2: 0.7500\n",
      "Epoch 11/15\n",
      "1/2 [==============>...............] - ETA: 3s - loss: 0.2268 - acc: 0.9375 - precision_2: 1.0000 - recall_2: 0.6875"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jspc8\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\PIL\\Image.py:992: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 8s 5s/step - loss: 0.1952 - acc: 0.9531 - precision_2: 1.0000 - recall_2: 0.7188 - val_loss: 0.1584 - val_acc: 0.9688 - val_precision_2: 1.0000 - val_recall_2: 0.7812\n",
      "Epoch 12/15\n",
      "2/2 [==============================] - 8s 5s/step - loss: 0.1152 - acc: 0.9688 - precision_2: 0.9825 - recall_2: 0.8750 - val_loss: 0.2159 - val_acc: 0.9375 - val_precision_2: 0.9630 - val_recall_2: 0.8125\n",
      "Epoch 13/15\n",
      "2/2 [==============================] - 8s 5s/step - loss: 0.1472 - acc: 0.9531 - precision_2: 1.0000 - recall_2: 0.8125 - val_loss: 0.1375 - val_acc: 0.9375 - val_precision_2: 1.0000 - val_recall_2: 0.7812\n",
      "Epoch 14/15\n",
      "2/2 [==============================] - 8s 5s/step - loss: 0.1544 - acc: 0.9375 - precision_2: 0.9808 - recall_2: 0.7969 - val_loss: 0.2399 - val_acc: 0.8750 - val_precision_2: 0.9600 - val_recall_2: 0.7500\n",
      "Epoch 15/15\n",
      "2/2 [==============================] - 8s 5s/step - loss: 0.1474 - acc: 0.9531 - precision_2: 0.9804 - recall_2: 0.7812 - val_loss: 0.1563 - val_acc: 0.9688 - val_precision_2: 1.0000 - val_recall_2: 0.7500\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(generator=train_generator,\n",
    "                              steps_per_epoch=len(train_generator)//32,\n",
    "                              epochs=15\n",
    "                              ,validation_data=test_generator,\n",
    "                              validation_steps=len(test_generator)//32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zmBIuIQ-MaMh",
    "outputId": "ea05dc13-0042-4077-812f-3c84d97a29b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 18s 2s/step - loss: 0.1869 - acc: 0.9554 - precision_2: 0.9780 - recall_2: 0.7946\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc, test_precision, test_recall = model.evaluate(test_generator, steps=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "C8uYxkF5QyXF"
   },
   "outputs": [],
   "source": [
    "model.save('Dl_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "xuWCjXY8P9S6"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "Br_1sHoTJM60"
   },
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model('Dl_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.74828106, 0.18351752]], dtype=float32)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(r'C:\\Users\\jspc8\\Downloads\\Behind the Mask\\Behind the Mask\\sample\\1.jpg')\n",
    "\n",
    "img = cv2.resize(img,(128,128)) \n",
    "img = np.reshape(img, [1,128,128,3])/255.0\n",
    "\n",
    "pred_prob = new_model.predict(img)\n",
    "\n",
    "pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "-TbdajGaQqnh"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04697245, 0.8383082 ]], dtype=float32)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(r'C:\\Users\\jspc8\\Downloads\\Behind the Mask\\Behind the Mask\\sample\\14.png')\n",
    "#plt.imshow(img)\n",
    "\n",
    "img = cv2.resize(img,(128,128)) \n",
    "img = np.reshape(img, [1,128,128,3])/255.0\n",
    "\n",
    "pred_prob = new_model.predict(img)\n",
    "\n",
    "pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.93253064, 0.02053204]], dtype=float32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(r'C:\\Users\\jspc8\\Downloads\\Behind the Mask\\Behind the Mask\\sample\\34.png')\n",
    "#plt.imshow(img)\n",
    "\n",
    "img = cv2.resize(img,(128,128)) \n",
    "img = np.reshape(img, [1,128,128,3])/255.0\n",
    "\n",
    "pred_prob = new_model.predict(img)\n",
    "\n",
    "pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.34603882, 0.3204388 ]], dtype=float32)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(r'C:\\Users\\jspc8\\Downloads\\Behind the Mask\\Behind the Mask\\sample\\81.png')\n",
    "#plt.imshow(img)\n",
    "\n",
    "img = cv2.resize(img,(128,128)) \n",
    "img = np.reshape(img, [1,128,128,3])/255.0\n",
    "\n",
    "pred_prob = new_model.predict(img)\n",
    "\n",
    "pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "dl project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
